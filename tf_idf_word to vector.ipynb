{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cc269935-2946-441a-bcc6-7dc9c56ef36c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d22409e6-752d-49b2-b1e3-aa35a91f5797",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    text\n",
      "0   people watch campusx\n",
      "1  campusx watch campusx\n",
      "2   people write comment\n",
      "3  campusx write comment\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame({\n",
    "    'text': [\n",
    "        'people watch campusx',\n",
    "        'campusx watch campusx',\n",
    "        'people write comment',\n",
    "        'campusx write comment'\n",
    "    ],\n",
    "})\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bab82ad4-efc7-49e4-a675-d548b80e78a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.49681612, 0.        , 0.61366674, 0.61366674, 0.        ],\n",
       "       [0.8508161 , 0.        , 0.        , 0.52546357, 0.        ],\n",
       "       [0.        , 0.57735027, 0.57735027, 0.        , 0.57735027],\n",
       "       [0.49681612, 0.61366674, 0.        , 0.        , 0.61366674]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Initialize the vectorizer\n",
    "tfidf = TfidfVectorizer()\n",
    "\n",
    "# Fit on text data and transform into TF-IDF feature vectors\n",
    "tfidf.fit_transform(df['text']).toarray()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ae080daf-3d25-4517-a3bd-e6f227d501e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.22314355 1.51082562 1.51082562 1.51082562 1.51082562]\n",
      "['campusx' 'comment' 'people' 'watch' 'write']\n"
     ]
    }
   ],
   "source": [
    "print(tfidf.idf_)\n",
    "print(tfidf.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c8bedb96-b61b-42a9-9be3-0c7b13a75c3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of words in the corpus: 12\n",
      "Total number of unique words (vocabulary): 6\n",
      "Vocabulary: {'comment', 'campusx', 'write', 'people', 'watch', 'campus'}\n"
     ]
    }
   ],
   "source": [
    "# Sample corpus\n",
    "corpus = [\n",
    "    \"people watch campusx\",\n",
    "    \"campusx watch campusx\",\n",
    "    \"people write comment\",\n",
    "    \"campus write comment\"\n",
    "]\n",
    "\n",
    "# Step 1: Combine all sentences into one string\n",
    "all_text = \" \".join(corpus)\n",
    "\n",
    "# Step 2: Split into individual words\n",
    "words = all_text.split()\n",
    "\n",
    "# Step 3: Find total number of words\n",
    "total_words = len(words)\n",
    "\n",
    "# Step 4: Find total number of unique words (vocabulary)\n",
    "unique_words = set(words)\n",
    "vocab_size = len(unique_words)\n",
    "\n",
    "# Display results\n",
    "print(\"Total number of words in the corpus:\", total_words)\n",
    "print(\"Total number of unique words (vocabulary):\", vocab_size)\n",
    "print(\"Vocabulary:\", unique_words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cb99c7bf-549d-4a67-b42d-b660131d56dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- BIGRAMS -----\n",
      "Vocabulary size: 6\n",
      "Vocabulary: ['campus write' 'campusx watch' 'people watch' 'people write'\n",
      " 'watch campusx' 'write comment']\n",
      "\n",
      "----- TRIGRAMS -----\n",
      "Vocabulary size: 4\n",
      "Vocabulary: ['campus write comment' 'campusx watch campusx' 'people watch campusx'\n",
      " 'people write comment']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import pandas as pd\n",
    "\n",
    "# Sample corpus\n",
    "corpus = [\n",
    "    \"people watch campusx\",\n",
    "    \"campusx watch campusx\",\n",
    "    \"people write comment\",\n",
    "    \"campus write comment\"\n",
    "]\n",
    "\n",
    "# Bag of Bigrams (2-grams)\n",
    "bigram_vectorizer = CountVectorizer(ngram_range=(2, 2))\n",
    "X_bigram = bigram_vectorizer.fit_transform(corpus)\n",
    "bigram_vocab = bigram_vectorizer.get_feature_names_out()\n",
    "\n",
    "# Bag of Trigrams (3-grams)\n",
    "trigram_vectorizer = CountVectorizer(ngram_range=(3, 3))\n",
    "X_trigram = trigram_vectorizer.fit_transform(corpus)\n",
    "trigram_vocab = trigram_vectorizer.get_feature_names_out()\n",
    "\n",
    "# Display results\n",
    "print(\"----- BIGRAMS -----\")\n",
    "print(\"Vocabulary size:\", len(bigram_vocab))\n",
    "print(\"Vocabulary:\", bigram_vocab)\n",
    "\n",
    "print(\"\\n----- TRIGRAMS -----\")\n",
    "print(\"Vocabulary size:\", len(trigram_vocab))\n",
    "print(\"Vocabulary:\", trigram_vocab)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0e9fecd-2e08-43b0-8c08-90b31343198f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "752d1d95-891d-4572-82a4-d05f6413f994",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
